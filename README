AI-Powered Music Visualizer Editor
A professional-grade music visualization application that combines real-time AI analysis with stunning OpenGL graphics. The application analyzes audio files using machine learning to detect tempo, beats, and emotional mood, then creates synchronized visual effects that respond to the music in real-time.
üéµ Features
Core Functionality

Real-time Audio Playback - Built-in audio engine with volume control
AI Music Analysis - Automatic tempo detection and mood classification
Dynamic Visualizations - OpenGL-powered effects synchronized to music
Beat Detection - Real-time beat tracking with visual indicators
Mood Classification - AI-powered emotion detection (Happy, Sad, Energetic, Calm, Angry)
Manual Controls - Override AI settings with manual mood selection

Visual Effects

Animated Waveforms - Real-time waveform display synced to audio
Beat Indicators - Pulsing circles that flash on detected beats
Frequency Spectrum - 32-band frequency visualization
Mood Particles - Dynamic particle system with mood-based colors
Adaptive Colors - Background and effects change based on detected mood

Technical Features

Cross-Platform - Windows, macOS, and Linux support
Optimized Performance - 60fps smooth animations with resource management
Audio Format Support - Supports MP3, WAV, and other common formats
Export Ready - Framework for video export functionality

üöÄ Quick Start
bash# 1. Navigate to project directory
cd AI-Powered-Music-Visualizer-Editor

# 2. Activate virtual environment
source venv/Scripts/activate  # Windows
# source venv/bin/activate    # macOS/Linux

# 3. Install Python dependencies (if not already installed)
pip install librosa numpy soundfile scikit-learn matplotlib pybind11 pyzmq torch

# 4. Build the application
mkdir build && cd build
cmake .. -G "MinGW Makefiles" -DCMAKE_MAKE_PROGRAM=C:/Qt/Tools/mingw1310_64/bin/mingw32-make.exe
cmake --build .

# 5. Run the application
./MusicVisualizer.exe  # Windows
# ./MusicVisualizer      # macOS/Linux
üìã Detailed Installation Guide
Prerequisites
System Requirements

Operating System: Windows 10+, macOS 10.15+, or Ubuntu 18.04+
RAM: 4GB minimum, 8GB recommended
GPU: OpenGL 3.3+ compatible graphics card
Audio: Working audio output device

Required Software

Qt 6.9.0+

Download from qt.io
Select Qt 6.x with appropriate compiler (MSVC/MinGW for Windows)


Python 3.9+

Download from python.org
Ensure Python is added to PATH during installation


CMake 3.16+

Download from cmake.org
Add to system PATH during installation


Git (for cloning)

Download from git-scm.com



Installation Steps
1. Clone the Repository
bashgit clone https://github.com/Myrmecology/AI-Powered-Music-Visualizer-Editor.git
cd AI-Powered-Music-Visualizer-Editor
2. Set Up Python Environment
bash# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt
# Or install individually:
pip install librosa numpy soundfile scikit-learn matplotlib pybind11 pyzmq torch
3. Configure Qt Path (if needed)
If Qt is not in your system PATH, you may need to set the Qt path manually:
Windows (MinGW):
bashexport CMAKE_PREFIX_PATH="C:/Qt/6.9.0/mingw_64/lib/cmake"
Windows (MSVC):
bashexport CMAKE_PREFIX_PATH="C:/Qt/6.9.0/msvc2019_64/lib/cmake"
4. Build the Application
bash# Create build directory
mkdir build
cd build

# Configure with CMake
# Windows (MinGW):
cmake .. -G "MinGW Makefiles" -DCMAKE_MAKE_PROGRAM=C:/Qt/Tools/mingw1310_64/bin/mingw32-make.exe

# Windows (MSVC):
cmake .. -G "Visual Studio 17 2022" -A x64

# macOS/Linux:
cmake ..

# Build the project
cmake --build . --config Release
üéÆ User Interface Guide
Main Window Components
Control Panel
The application features an intuitive control panel with the following buttons and elements:
Primary Controls

Load Audio - Opens file dialog to select audio files (MP3, WAV supported)
Analyze - Processes the loaded audio using AI algorithms
Play - Starts audio playback and visualization
Stop - Stops audio playback and pauses visualization
Refresh - Resets all processes and clears memory (use if performance degrades)
Export Video - Opens dialog for video export (framework in place)

Audio Controls

Volume Slider - Adjusts audio output volume (0-100%)

Located below the main control buttons
Real-time volume adjustment during playback



Mood Override Controls
Manual mood selection buttons that override AI detection:

Happy - Sets warm orange color scheme
Sad - Sets cool blue color scheme
Energetic - Sets vibrant red/pink color scheme
Calm - Sets soft green color scheme
Angry - Sets intense red color scheme

Status Bar
Located at the top of the control panel, displays current application state:

"Ready to visualize music" - Initial state
"Loaded: [filename]" - When audio file is loaded
"Analyzing audio..." - During AI processing
"Analysis complete - Tempo: X BPM, Mood: Y" - After successful analysis
"Playing audio and visualization..." - During playback
"Stopped" - When playback is stopped

Visualization Area
The main display area shows real-time graphics:

Background - Changes color based on detected or selected mood
Waveform - Animated line graph showing audio amplitude
Beat Indicator - White circle at top that pulses on beats
Frequency Bars - 32 vertical bars representing frequency spectrum
Mood Particles - Floating particles colored by current mood

üîÑ Workflow and Usage
Basic Usage Workflow

Launch Application
bashcd build
./MusicVisualizer.exe

Load Audio File

Click "Load Audio" button
Select an audio file (.mp3 or .wav)
Status will show "Loaded: [filename]"


Analyze Audio (Optional but Recommended)

Click "Analyze" button (enabled after loading audio)
Wait for analysis to complete
Status will show detected tempo and mood


Play and Visualize

Click "Play" button
Audio will play through speakers/headphones
Visual effects will appear synchronized to the music


Control Visualization

Adjust volume with slider
Try different mood overrides
Click "Stop" to pause
Use "Refresh" if performance degrades



Advanced Features
AI Analysis Details
The analysis process performs:

Tempo Detection - Identifies BPM (beats per minute)
Beat Tracking - Locates individual beat positions
Mood Classification - Uses neural network to classify emotional content
Feature Extraction - Analyzes spectral characteristics

Visualization Synchronization

Beat-aligned Effects - Visual pulses match detected beats
Tempo-dependent Animation - Animation speed scales with BPM
Dynamic Color Mapping - Colors reflect musical mood
Frequency Response - Spectrum display shows real audio frequencies

üõ†Ô∏è Technical Details
Architecture Overview
Core Components

Qt/C++ Frontend - User interface and real-time graphics
Python Backend - AI analysis and audio processing
OpenGL Renderer - Hardware-accelerated visualization
Inter-process Communication - C++ ‚Üî Python coordination

Technology Stack

Frontend: Qt 6.9.0, OpenGL 3.3+, C++17
Backend: Python 3.9+, librosa, PyTorch/TensorFlow
Audio: QtMultimedia, FFmpeg codec support
Build System: CMake 3.16+
Communication: QProcess, JSON data exchange

Performance Optimizations

60 FPS Rendering - Smooth animation with vsync
Resource Management - Automatic cleanup of processes
Memory Efficiency - Optimized data structures
Timer Reset - Prevents timing drift during long sessions

Supported Audio Formats

MP3 - Most common compressed format
WAV - Uncompressed audio (best quality)
FLAC - Lossless compression (via FFmpeg)
OGG - Open-source compressed format
M4A/AAC - Apple formats (via FFmpeg)

AI Model Details

Tempo Detection - librosa beat tracking algorithms
Mood Classification - Custom neural network with 5 mood categories
Feature Extraction - MFCCs, spectral features, rhythm analysis
Confidence Scoring - Model provides confidence percentages

üß™ Testing and Validation
Testing Your Installation
Python Component Test
bash# Test audio analysis
python main.py analyze "path/to/audio/file.mp3"

# Test mood classification
python main.py classify "path/to/audio/file.mp3"

# Start analysis server
python main.py server
Expected Output
Analysis should show:

Duration in seconds
Sample rate (typically 44100 Hz)
Detected tempo in BPM
Beat count
Predicted mood with confidence

Performance Benchmarks

Startup Time: < 3 seconds
Analysis Speed: 2-5x real-time
Memory Usage: < 500MB typical
CPU Usage: < 15% on modern systems
Frame Rate: 60 FPS sustained

üêõ Troubleshooting
Common Issues and Solutions
Audio Not Playing
Problem: Visuals work but no sound
Solutions:

Check system volume and audio device
Restart Windows Audio Service:
cmdnet stop audiosrv
net start audiosrv

Try different audio format (MP3 vs WAV)
Use "Refresh" button to reset audio system

Analysis Button Not Working
Problem: Analyze button doesn't respond
Solutions:

Ensure Python virtual environment is activated
Check Python dependencies are installed
Verify audio file path has no special characters
Use "Refresh" button to reset analysis client

Performance Degradation
Problem: Animation becomes slow over time
Solutions:

Click "Refresh" button (recommended)
Restart application
Check available system memory
Close other resource-intensive applications

Build Errors
Problem: Compilation fails
Solutions:

Verify Qt installation and PATH
Update CMake to latest version
Install required system libraries
Check compiler compatibility

Debug Mode
To enable debug output:
bash# Set environment variable
export QT_LOGGING_RULES="*.debug=true"

# Run application
./MusicVisualizer.exe
üìÅ Project Structure
AI-Powered-Music-Visualizer-Editor/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ cpp/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.cpp              # Main application entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyzer_client.h     # Python communication header
‚îÇ   ‚îî‚îÄ‚îÄ python/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py           # Python package initialization
‚îÇ       ‚îú‚îÄ‚îÄ audio_analyzer.py     # Audio analysis algorithms
‚îÇ       ‚îú‚îÄ‚îÄ mood_classifier.py    # AI mood classification
‚îÇ       ‚îî‚îÄ‚îÄ analysis_server.py    # Python-C++ communication server
‚îú‚îÄ‚îÄ build/                        # Build output directory
‚îú‚îÄ‚îÄ assets/                       # Audio files and resources (optional)
‚îú‚îÄ‚îÄ ui/                          # Additional UI resources (for future use)
‚îú‚îÄ‚îÄ venv/                        # Python virtual environment
‚îú‚îÄ‚îÄ .vscode/                     # VS Code configuration
‚îú‚îÄ‚îÄ .gitignore                   # Git ignore rules
‚îú‚îÄ‚îÄ CMakeLists.txt              # CMake build configuration
‚îú‚îÄ‚îÄ main.py                     # Python CLI entry point
‚îú‚îÄ‚îÄ launch.bat                  # Windows launch script
‚îú‚îÄ‚îÄ launch.sh                   # Unix launch script
‚îî‚îÄ‚îÄ README.md                   # This documentation
üîß Customization Guide
Adding New Mood Categories

Update mood list in mood_classifier.py
Retrain neural network with new categories
Add color mappings in C++ visualization code
Update UI buttons for new moods

Modifying Visual Effects

Edit drawing functions in VisualizerWidget class
Adjust colors, shapes, or animation parameters
Add new effect types in paintGL() method
Compile and test changes

Audio Format Support

Ensure FFmpeg codecs are available
Update file dialog filters in loadAudioFile()
Test compatibility with new formats
Update documentation

üìÑ License
This project is licensed under the MIT License - see the LICENSE file for details.
ü§ù Contributing
Contributions are welcome! Please read our Contributing Guidelines for details on our code of conduct and the process for submitting pull requests.
Development Setup

Fork the repository
Create a feature branch
Make your changes
Add tests for new functionality
Ensure all tests pass
Submit a pull request

üìû Support

Issues: GitHub Issues
Discussions: GitHub Discussions
Documentation: This README and in-code comments

üéâ Acknowledgments

Qt Framework - For providing robust cross-platform GUI capabilities
librosa - For excellent audio analysis libraries
PyTorch - For machine learning infrastructure
FFmpeg - For comprehensive audio codec support
OpenGL - For hardware-accelerated graphics

üöß Roadmap
Planned Features

 Video export functionality
 Real-time MIDI/DMX light control
 Additional visualization modes
 Batch processing of audio files
 Plugin architecture for custom effects
 Advanced audio effects (reverb, compression)
 Cloud-based mood model training
 Mobile app companion

Version History

v1.0.0 - Initial release with core visualization and AI features
v1.1.0 - Added refresh button and improved resource management
v1.2.0 - Enhanced audio format support and performance optimizations


Build amazing visualizations and let the music guide your creativity! üéµ‚ú®

## I have future plans for this project, but for now it's ready to go.

## HAPPY CODING everyone!üéâ

